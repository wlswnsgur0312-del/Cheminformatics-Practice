# ğŸ§¬ Project 1: AI-Driven Discovery of EGFR Inhibitors (Lung Cancer)

## ğŸ“Œ 1. ì—°êµ¬ ê°œìš” (Overview)
ë³¸ í”„ë¡œì íŠ¸ëŠ” **ë¹„ì†Œì„¸í¬íì•”(NSCLC)**ì˜ ì£¼ìš” í‘œì  ë‹¨ë°±ì§ˆì¸ **EGFR(Epidermal Growth Factor Receptor)**ì„ ì–µì œí•˜ëŠ” ì•½ë¬¼ì„ ë°œêµ´í•˜ê¸° ìœ„í•œ **ì¸ê³µì§€ëŠ¥(QSAR) ë¶„ë¥˜ ëª¨ë¸**ì„ ê°œë°œí•˜ëŠ” ì—°êµ¬ì…ë‹ˆë‹¤.

ChEMBL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ 57,000ê±´ ì´ìƒì˜ ì‹¤ì œ ì•½ë¬¼ í™œì„± ë°ì´í„°(Bioactivity Data)ë¥¼ ì¶”ì¶œí•˜ê³ , **Random Forest** ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ë¶„ì êµ¬ì¡°ì™€ ì•½íš¨ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.

---

## ğŸ› ï¸ 2. ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)
| Category | Tools Used |
|----------|------------|
| **Language** | Python 3.10 |
| **Cheminformatics** | RDKit |
| **Machine Learning** | Scikit-learn (Random Forest) |
| **Data Processing** | Pandas, NumPy |
| **Data Source** | ChEMBL Database (ID: CHEMBL203) |

---

## ğŸ“Š 3. ì—°êµ¬ ê³¼ì • ë° ë°©ë²• (Methodology)

### Step 1: Data Mining & Preprocessing
* **Source**: ChEMBL APIë¥¼ í†µí•´ EGFR íƒ€ê²Ÿ(`CHEMBL203`)ì— ëŒ€í•œ IC50 ë°ì´í„°ë¥¼ ìˆ˜ì§‘.
* **Cleaning**: ê²°ì¸¡ì¹˜ ì œê±° ë° ë‹¨ìœ„ í†µì¼ (Standard Unit: nM).
* **Labeling**: IC50 â‰¤ 1000 nMì¸ ê²½ìš°ë¥¼ **Active(1)**, ì´ˆê³¼ì¸ ê²½ìš°ë¥¼ **Inactive(0)**ë¡œ ì •ì˜.

### Step 2: Feature Engineering (RDKit)
ê° í™”í•©ë¬¼ì˜ SMILES êµ¬ì¡°ë¡œë¶€í„° ë‹¤ìŒì˜ 4ê°€ì§€ ë¬¼ë¦¬í™”í•™ì  íŠ¹ì„±ì„ ì¶”ì¶œí•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©:
1.  **Molecular Weight (MW)**: ë¶„ìëŸ‰
2.  **LogP**: ì§€ì§ˆì¹œí™”ë„ (Lipophilicity)
3.  **NumRotatableBonds**: íšŒì „ ê°€ëŠ¥í•œ ê²°í•© ìˆ˜ (ìœ ì—°ì„±)
4.  **TPSA**: ê·¹ì„± í‘œë©´ì  (ì„¸í¬ë§‰ íˆ¬ê³¼ì„± ê´€ë ¨)

### Step 3: Model Training
* **Algorithm**: Random Forest Classifier
* **Dataset Split**: Training (80%) / Test (20%)
* **Hyperparameters**: `n_estimators=100`, `random_state=42`

---

## ğŸ“ˆ 4. ì—°êµ¬ ê²°ê³¼ (Results)

ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(Test Set)ì— ëŒ€í•´ **84.32%**ì˜ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

### [Performance Log]
```text
--- 3. AI ëª¨ë¸ í•™ìŠµ ì‹œì‘! (í•™ìŠµ ë°ì´í„°: 31597ê°œ) ---

>>> [ìµœì¢… ê²°ê³¼] AI ì •í™•ë„: 84.32%

```python

import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np

print("--- 1. ChEMBL ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... ---")

# 1. CSV íŒŒì¼ ì½ê¸°
try:
    df = pd.read_csv('chembl_data.csv', sep=';', low_memory=False)
except FileNotFoundError:
    print("ì˜¤ë¥˜: 'chembl_data.csv' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í´ë” ìœ„ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ì—‘ì…€ì˜ "Standard Value" -> "standard_value"ë¡œ ìë™ ë³€í™˜ (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

print(f">> ì „ì²´ ë°ì´í„° ê°œìˆ˜: {len(df)}ê°œ")

# 2. ë°ì´í„° ì „ì²˜ë¦¬ (ì²­ì†Œí•˜ê¸°)
# SMILES ì»¬ëŸ¼ ì´ë¦„ì´ ë²„ì „ë§ˆë‹¤ ë‹¬ë¼ì„œ ì°¾ì•„ë‚´ëŠ” ì½”ë“œ
if 'canonical_smiles' in df.columns:
    smiles_col = 'canonical_smiles'
elif 'smiles' in df.columns:
    smiles_col = 'smiles'
else:
    print(f"ì˜¤ë¥˜: SMILES ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
    exit()

# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
df = df[[smiles_col, 'standard_value']].dropna()

# 'standard_value'ë¥¼ ìˆ«ìë¡œ ê°•ì œ ë³€í™˜ (ë¬¸ìì—´ì´ ì„ì—¬ìˆìœ¼ë©´ ì—ëŸ¬ ë‚˜ë¯€ë¡œ)
df['standard_value'] = pd.to_numeric(df['standard_value'], errors='coerce')
df = df.dropna(subset=['standard_value']) # ë³€í™˜ ì•ˆ ë˜ëŠ” ì´ìƒí•œ ê°’ ì‚­ì œ

# ì•½íš¨ ë¶„ë¥˜ (Labeling): 1000nM ì´í•˜ë©´ í™œì„±(1), ì•„ë‹ˆë©´ ë¹„í™œì„±(0)
df['Active_Label'] = df['standard_value'].apply(lambda x: 1 if x <= 1000 else 0)

print(f">> í•™ìŠµì— ì‚¬ìš©í•  ìœ íš¨ ë°ì´í„°: {len(df)}ê°œ (ì „ì²˜ë¦¬ ì™„ë£Œ)")

# 3. íŠ¹ì§•(Feature) ì¶”ì¶œ í•¨ìˆ˜
def get_descriptors(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol:
            return [
                Descriptors.MolWt(mol),        # ë¶„ìëŸ‰
                Descriptors.MolLogP(mol),      # ì§€ì§ˆì¹œí™”ë„
                Descriptors.NumRotatableBonds(mol), # íšŒì „ê°€ëŠ¥ ê²°í•© ìˆ˜
                Descriptors.TPSA(mol)          # ê·¹ì„± í‘œë©´ì 
            ]
    except:
        return None
    return None

print("--- 2. ë¶„ì íŠ¹ì§• ì¶”ì¶œ ì¤‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)... ---")
print("    (ë©ˆì¶˜ ê²Œ ì•„ë‹ˆë‹ˆ ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!)")

# ë°ì´í„° ì „ì²´ì— ì ìš© (progress barê°€ ì—†ì–´ì„œ ê·¸ëƒ¥ ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤)
df['Features'] = df[smiles_col].apply(get_descriptors)

# ê³„ì‚° ì‹¤íŒ¨í•œ ë°ì´í„° ì‚­ì œ
df = df.dropna(subset=['Features'])

# 4. AI í•™ìŠµ ì¤€ë¹„
X = list(df['Features'])
y = df['Active_Label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"--- 3. AI ëª¨ë¸ í•™ìŠµ ì‹œì‘! (í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ) ---")
# ë‚˜ë¬´ 100ê·¸ë£¨ ì‹¬ê¸° (ë°ì´í„°ê°€ ë§ìœ¼ë‹ˆ 100ê°œ ì •ë„ëŠ” ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 5. ê²°ê³¼ í™•ì¸
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"\n>>> [ìµœì¢… ê²°ê³¼] AI ì •í™•ë„: {accuracy*100:.2f}%")
print("ì¶•í•˜í•©ë‹ˆë‹¤! ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ ì´ìš©í•œ QSAR ëª¨ë¸ë§ì— ì„±ê³µí•˜ì…¨ìŠµë‹ˆë‹¤.")
